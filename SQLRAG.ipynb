{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI API configuration\n",
    "# Initialize the client\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# PostgreSQL database connection\n",
    "DB_PARAMS = {\n",
    "    \"dbname\": \"mydatabase\",\n",
    "    \"user\": \"myuser\",\n",
    "    \"password\": \"mypassword\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5433\"  # Ensure this matches your PostgreSQL container port\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_connection():\n",
    "    \"\"\"Create and return database connection and cursor\"\"\"\n",
    "    conn = psycopg2.connect(**DB_PARAMS)\n",
    "    cur = conn.cursor()\n",
    "    return conn, cur\n",
    "\n",
    "def fetch_all_metadata():\n",
    "    \"\"\"Fetch metadata for all tables\"\"\"\n",
    "    conn, cur = get_db_connection()\n",
    "    \n",
    "    try:\n",
    "        # Get metadata for all tables\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT table_name, description, table_purpose, columns_info, \n",
    "                   primary_keys, foreign_keys, important_considerations,\n",
    "                   common_joins, example_questions\n",
    "            FROM mimic_table_metadata;\n",
    "        \"\"\")\n",
    "        \n",
    "        all_metadata = cur.fetchall()\n",
    "        \n",
    "        # Format metadata as dictionary\n",
    "        tables_metadata = {}\n",
    "        for row in all_metadata:\n",
    "            table_name = row[0]\n",
    "            tables_metadata[table_name] = {\n",
    "                'description': row[1],\n",
    "                'table_purpose': row[2],\n",
    "                'columns_info': row[3],\n",
    "                'primary_keys': row[4],\n",
    "                'foreign_keys': row[5],\n",
    "                'important_considerations': row[6],\n",
    "                'common_joins': row[7],\n",
    "                'example_questions': row[8]\n",
    "            }\n",
    "        \n",
    "        return tables_metadata\n",
    "    \n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "\n",
    "def format_metadata_for_prompt(metadata):\n",
    "    \"\"\"Format metadata into text suitable for LLM prompt\"\"\"\n",
    "    formatted_text = \"# Database Schema Information\\n\\n\"\n",
    "    \n",
    "    for table_name, table_info in metadata.items():\n",
    "        formatted_text += f\"## Table: {table_name}\\n\"\n",
    "        formatted_text += f\"Description: {table_info['description']}\\n\"\n",
    "        formatted_text += f\"Purpose: {table_info['table_purpose']}\\n\\n\"\n",
    "        \n",
    "        # Add primary key information\n",
    "        if table_info['primary_keys']:\n",
    "            formatted_text += f\"Primary Keys: {', '.join(table_info['primary_keys'])}\\n\\n\"\n",
    "        \n",
    "        # Add foreign key information\n",
    "        if table_info['foreign_keys']:\n",
    "            formatted_text += \"Foreign Keys:\\n\"\n",
    "            for fk_col, fk_info in table_info['foreign_keys'].items():\n",
    "                formatted_text += f\"- {fk_col} references {fk_info['table']}.{fk_info['column']}\\n\"\n",
    "            formatted_text += \"\\n\"\n",
    "        \n",
    "        # Add column information\n",
    "        formatted_text += \"Columns:\\n\"\n",
    "        for col_name, col_info in table_info['columns_info'].items():\n",
    "            formatted_text += f\"- {col_name} ({col_info['data_type']}): {col_info['description']}\\n\"\n",
    "            \n",
    "            # Add categorical value distribution if available and not too long\n",
    "            if 'categorical_values' in col_info and len(col_info['categorical_values']) < 15:\n",
    "                formatted_text += f\"  Possible values: {', '.join(col_info['categorical_values'])}\\n\"\n",
    "            \n",
    "            # Add value range if available\n",
    "            if 'value_range' in col_info:\n",
    "                formatted_text += f\"  Range: {col_info['value_range']['min']} to {col_info['value_range']['max']}\\n\"\n",
    "        \n",
    "        formatted_text += \"\\n\"\n",
    "        \n",
    "        # Add important considerations\n",
    "        if table_info['important_considerations']:\n",
    "            formatted_text += f\"Important Considerations: {table_info['important_considerations']}\\n\\n\"\n",
    "        \n",
    "        # Add common joins\n",
    "        if table_info['common_joins']:\n",
    "            formatted_text += \"Common Joins:\\n\"\n",
    "            for join in table_info['common_joins']:\n",
    "                formatted_text += f\"- {join}\\n\"\n",
    "            formatted_text += \"\\n\"\n",
    "        \n",
    "        formatted_text += \"---\\n\\n\"\n",
    "    \n",
    "    return formatted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llm_prompt(user_question, metadata_text):\n",
    "    \"\"\"Create the complete prompt to send to the LLM\"\"\"\n",
    "    prompt = f\"\"\"You are a professional medical database expert specializing in SQL and the MIMIC-IV database. Based on the user's question and the provided database metadata, generate a PostgreSQL query.\n",
    "\n",
    "## User Question\n",
    "{user_question}\n",
    "\n",
    "## Database Metadata\n",
    "{metadata_text}\n",
    "\n",
    "## Task\n",
    "1. Analyze the user question to determine which tables and columns need to be queried\n",
    "2. Design an effective SQL query based on the provided metadata\n",
    "3. Ensure the generated SQL is syntactically correct and considers table relationships\n",
    "4. If multiple table joins are needed, use the correct join conditions\n",
    "5. Handle any potential edge cases\n",
    "\n",
    "## Response Format\n",
    "Please return ONLY the SQL query without any explanation. Start your answer with \"SELECT\".\n",
    "\n",
    "SQL Query:\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_with_openai(prompt):\n",
    "    \"\"\"Generate SQL query using OpenAI API (updated for version 1.0+)\"\"\"\n",
    "    try:\n",
    "        # Using the new client format\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",  # or another suitable model\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a medical database expert who converts natural language questions into PostgreSQL queries.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.1,  # Low temperature for more deterministic output\n",
    "            max_tokens=500\n",
    "        )\n",
    "        \n",
    "        # Updated way to access response content\n",
    "        sql_query = response.choices[0].message.content.strip()\n",
    "        \n",
    "        # Remove \"SQL Query:\" prefix if present\n",
    "        if sql_query.startswith(\"SQL Query:\"):\n",
    "            sql_query = sql_query[len(\"SQL Query:\"):].strip()\n",
    "        \n",
    "        return sql_query\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error calling OpenAI API: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def execute_sql_query(sql_query):\n",
    "    \"\"\"Execute SQL query and return results\"\"\"\n",
    "    conn, cur = get_db_connection()\n",
    "    \n",
    "    try:\n",
    "        cur.execute(sql_query)\n",
    "        \n",
    "        # Get column names\n",
    "        column_names = [desc[0] for desc in cur.description]\n",
    "        \n",
    "        # Get query results\n",
    "        results = cur.fetchall()\n",
    "        \n",
    "        # Convert results to DataFrame\n",
    "        df = pd.DataFrame(results, columns=column_names)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error executing SQL query: {e}\")\n",
    "        return None\n",
    "    \n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqlrag_pipeline(user_question):\n",
    "    \"\"\"Execute the complete SQLRAG pipeline\"\"\"\n",
    "    print(f\"User Question: {user_question}\")\n",
    "    print(\"Fetching metadata...\")\n",
    "    \n",
    "    # 1. Fetch metadata\n",
    "    metadata = fetch_all_metadata()\n",
    "    \n",
    "    # 2. Format metadata for prompt\n",
    "    metadata_text = format_metadata_for_prompt(metadata)\n",
    "    \n",
    "    # 3. Create LLM prompt\n",
    "    prompt = create_llm_prompt(user_question, metadata_text)\n",
    "    \n",
    "    print(\"Generating SQL with LLM...\")\n",
    "    # 4. Generate SQL query\n",
    "    sql_query = generate_sql_with_openai(prompt)\n",
    "    \n",
    "    if not sql_query:\n",
    "        return \"Failed to generate SQL query\"\n",
    "    \n",
    "    print(f\"Generated SQL: \\n{sql_query}\\n\")\n",
    "    \n",
    "    print(\"Executing SQL query...\")\n",
    "    # 5. Execute SQL query\n",
    "    results = execute_sql_query(sql_query)\n",
    "    \n",
    "    if results is None:\n",
    "        return \"Error executing SQL query\"\n",
    "    \n",
    "    print(\"Query Results:\")\n",
    "    print(results)\n",
    "    \n",
    "    return {\n",
    "        \"user_question\": user_question,\n",
    "        \"generated_sql\": sql_query,\n",
    "        \"results\": results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Question: Which patient has the highest number of hospital admissions?\n",
      "Fetching metadata...\n",
      "Generating SQL with LLM...\n",
      "Generated SQL: \n",
      "SELECT subject_id, COUNT(hadm_id) AS num_admissions\n",
      "FROM admissions\n",
      "GROUP BY subject_id\n",
      "ORDER BY num_admissions DESC\n",
      "LIMIT 1;\n",
      "\n",
      "Executing SQL query...\n",
      "Query Results:\n",
      "   subject_id  num_admissions\n",
      "0    15496609             238\n"
     ]
    }
   ],
   "source": [
    "# Test with user question\n",
    "if __name__ == \"__main__\":\n",
    "    # Example question\n",
    "    question = \"Which patient has the highest number of hospital admissions?\"\n",
    "    \n",
    "    # Run SQLRAG pipeline\n",
    "    result = sqlrag_pipeline(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
